{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anass2FPi-in"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'your_zip_file.zip' with the actual filename of your ZIP file\n",
        "zip_path = '/content/drive/MyDrive/satalite data-20240904T065410Z-001.zip'\n",
        "extract_path = '/content/satalite_data/'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f'Extracted files to {extract_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C98nAUiFjxlI",
        "outputId": "b9ff7607-73f2-4434-c635-39990791d2cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files to /content/satalite_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv9WOanyjx6r",
        "outputId": "154d74a7-43f0-4531-babf-749be79cc987"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (71.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.4)\n",
            "Downloading rasterio-1.3.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.11 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def load_tiff_image(image_path):\n",
        "    with rasterio.open(image_path) as src:\n",
        "        # Read all 12 bands\n",
        "        image = np.stack([src.read(i) for i in range(1, 13)], axis=-1)\n",
        "    return image\n",
        "\n",
        "def load_png_mask(mask_path):\n",
        "    # Load the mask as grayscale\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # Normalize the mask to [0, 1]\n",
        "    mask = mask / 255.0\n",
        "    return mask"
      ],
      "metadata": {
        "id": "s7Z8wgS_j-ar"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Example function to preprocess images and masks\n",
        "\n",
        "def preprocess_data(image_size=(256, 256)):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(0,306):\n",
        "        image = load_tiff_image('/content/satalite_data/satalite data-20240904T065410Z-001/satalite data/data/images/'+str(i)+'.tif')\n",
        "        mask = load_png_mask('/content/satalite_data/satalite data-20240904T065410Z-001/satalite data/data/labels/'+str(i)+\".png\")\n",
        "\n",
        "\n",
        "        X.append(image)\n",
        "        y.append(mask)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    y = np.expand_dims(y, axis=-1)  # Add channel dimension to masks\n",
        "\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Preprocess data\n",
        "X, y = preprocess_data()\n",
        "y_ = (y > 0).astype(int)\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_, test_size=0.2, random_state=42)\n",
        "\n",
        "#---Normalization\n",
        "\n",
        "def normalize_image(image):\n",
        "    # Normalize each band to [0, 1]\n",
        "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "\n",
        "X_train = np.array([normalize_image(img) for img in X_train])\n",
        "X_val = np.array([normalize_image(img) for img in X_val])\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "# Apply the augmentation only to the training set\n",
        "train_generator = datagen.flow(X_train, y_train, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEy7r58akGHj",
        "outputId": "5c41510f-bdc1-4e3c-f9e6-acdc146c571b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
            "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (244, 128, 128, 12) (12 channels).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "import torch\n",
        "import torchvision.models.segmentation as models\n",
        "\n",
        "# Load pretrained DeepLabV3\n",
        "model = models.deeplabv3_resnet50(pretrained=True)\n",
        "\n",
        "# Modify the first layer to accept 12 input channels\n",
        "model.backbone.conv1 = torch.nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Model summary (requires torchinfo package)\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=(1, 12, 128, 128))\n"
      ],
      "metadata": {
        "id": "24_U6jnSklLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66b53ce-7f42-46cd-8427-1031ac54c254"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
            "100%|██████████| 161M/161M [00:01<00:00, 163MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "DeepLabV3                                          [1, 21, 128, 128]         --\n",
              "├─IntermediateLayerGetter: 1-1                     [1, 2048, 16, 16]         --\n",
              "│    └─Conv2d: 2-1                                 [1, 64, 64, 64]           37,632\n",
              "│    └─BatchNorm2d: 2-2                            [1, 64, 64, 64]           128\n",
              "│    └─ReLU: 2-3                                   [1, 64, 64, 64]           --\n",
              "│    └─MaxPool2d: 2-4                              [1, 64, 32, 32]           --\n",
              "│    └─Sequential: 2-5                             [1, 256, 32, 32]          --\n",
              "│    │    └─Bottleneck: 3-1                        [1, 256, 32, 32]          75,008\n",
              "│    │    └─Bottleneck: 3-2                        [1, 256, 32, 32]          70,400\n",
              "│    │    └─Bottleneck: 3-3                        [1, 256, 32, 32]          70,400\n",
              "│    └─Sequential: 2-6                             [1, 512, 16, 16]          --\n",
              "│    │    └─Bottleneck: 3-4                        [1, 512, 16, 16]          379,392\n",
              "│    │    └─Bottleneck: 3-5                        [1, 512, 16, 16]          280,064\n",
              "│    │    └─Bottleneck: 3-6                        [1, 512, 16, 16]          280,064\n",
              "│    │    └─Bottleneck: 3-7                        [1, 512, 16, 16]          280,064\n",
              "│    └─Sequential: 2-7                             [1, 1024, 16, 16]         --\n",
              "│    │    └─Bottleneck: 3-8                        [1, 1024, 16, 16]         1,512,448\n",
              "│    │    └─Bottleneck: 3-9                        [1, 1024, 16, 16]         1,117,184\n",
              "│    │    └─Bottleneck: 3-10                       [1, 1024, 16, 16]         1,117,184\n",
              "│    │    └─Bottleneck: 3-11                       [1, 1024, 16, 16]         1,117,184\n",
              "│    │    └─Bottleneck: 3-12                       [1, 1024, 16, 16]         1,117,184\n",
              "│    │    └─Bottleneck: 3-13                       [1, 1024, 16, 16]         1,117,184\n",
              "│    └─Sequential: 2-8                             [1, 2048, 16, 16]         --\n",
              "│    │    └─Bottleneck: 3-14                       [1, 2048, 16, 16]         6,039,552\n",
              "│    │    └─Bottleneck: 3-15                       [1, 2048, 16, 16]         4,462,592\n",
              "│    │    └─Bottleneck: 3-16                       [1, 2048, 16, 16]         4,462,592\n",
              "├─DeepLabHead: 1-2                                 [1, 21, 16, 16]           --\n",
              "│    └─ASPP: 2-9                                   [1, 256, 16, 16]          --\n",
              "│    │    └─ModuleList: 3-17                       --                        15,206,912\n",
              "│    │    └─Sequential: 3-18                       [1, 256, 16, 16]          328,192\n",
              "│    └─Conv2d: 2-10                                [1, 256, 16, 16]          589,824\n",
              "│    └─BatchNorm2d: 2-11                           [1, 256, 16, 16]          512\n",
              "│    └─ReLU: 2-12                                  [1, 256, 16, 16]          --\n",
              "│    └─Conv2d: 2-13                                [1, 21, 16, 16]           5,397\n",
              "├─FCNHead: 1-3                                     [1, 21, 16, 16]           --\n",
              "│    └─Conv2d: 2-14                                [1, 256, 16, 16]          2,359,296\n",
              "│    └─BatchNorm2d: 2-15                           [1, 256, 16, 16]          512\n",
              "│    └─ReLU: 2-16                                  [1, 256, 16, 16]          --\n",
              "│    └─Dropout: 2-17                               [1, 256, 16, 16]          --\n",
              "│    └─Conv2d: 2-18                                [1, 21, 16, 16]           5,397\n",
              "====================================================================================================\n",
              "Total params: 42,032,298\n",
              "Trainable params: 42,032,298\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 10.95\n",
              "====================================================================================================\n",
              "Input size (MB): 0.79\n",
              "Forward/backward pass size (MB): 139.03\n",
              "Params size (MB): 168.13\n",
              "Estimated Total Size (MB): 307.94\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Convert numpy data to PyTorch tensors\n",
        "\n",
        "X_train_tensor = torch.Tensor(np.moveaxis(X_train, -1, 1)) # Move channels to the second dimension\n",
        "y_train_tensor = torch.Tensor(y_train).long()  # Ensure masks are of type long for CrossEntropyLoss\n",
        "X_val_tensor = torch.Tensor(np.moveaxis(X_val,-1,1)) # Move channels to the second dimension\n",
        "y_val_tensor = torch.Tensor(y_val).long()\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "# Define the scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "# Get the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n",
        "\n",
        "# Training loop with ReduceLROnPlateau\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, masks in train_loader:\n",
        "         # Move images and masks to the device\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)['out']\n",
        "        masks = masks.squeeze(-1)  # Remove extra dimension if necessary\n",
        "        loss = loss_fn(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Average training loss for the epoch\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Switch to evaluation mode and calculate validation loss\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            outputs = model(images)['out']\n",
        "            masks = masks.squeeze(-1)\n",
        "            loss = loss_fn(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Step the scheduler with the validation loss\n",
        "    scheduler.step(avg_val_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjSNhfx-DbEi",
        "outputId": "2223ab5d-1bca-43d0-e655-1d9a53975d20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Training Loss: 0.6278\n",
            "Epoch 1/25, Validation Loss: 0.5406\n",
            "Epoch 2/25, Training Loss: 0.4092\n",
            "Epoch 2/25, Validation Loss: 0.3482\n",
            "Epoch 3/25, Training Loss: 0.4617\n",
            "Epoch 3/25, Validation Loss: 0.3144\n",
            "Epoch 4/25, Training Loss: 0.3518\n",
            "Epoch 4/25, Validation Loss: 0.2497\n",
            "Epoch 5/25, Training Loss: 0.3240\n",
            "Epoch 5/25, Validation Loss: 0.2652\n",
            "Epoch 6/25, Training Loss: 0.3107\n",
            "Epoch 6/25, Validation Loss: 0.2894\n",
            "Epoch 7/25, Training Loss: 0.2511\n",
            "Epoch 7/25, Validation Loss: 0.2411\n",
            "Epoch 8/25, Training Loss: 0.2511\n",
            "Epoch 8/25, Validation Loss: 0.2501\n",
            "Epoch 9/25, Training Loss: 0.2298\n",
            "Epoch 9/25, Validation Loss: 0.2279\n",
            "Epoch 10/25, Training Loss: 0.2359\n",
            "Epoch 10/25, Validation Loss: 0.1981\n",
            "Epoch 11/25, Training Loss: 0.2211\n",
            "Epoch 11/25, Validation Loss: 0.1946\n",
            "Epoch 12/25, Training Loss: 0.2089\n",
            "Epoch 12/25, Validation Loss: 0.2253\n",
            "Epoch 13/25, Training Loss: 0.1971\n",
            "Epoch 13/25, Validation Loss: 0.2187\n",
            "Epoch 14/25, Training Loss: 0.1928\n",
            "Epoch 14/25, Validation Loss: 0.2822\n",
            "Epoch 15/25, Training Loss: 0.1700\n",
            "Epoch 15/25, Validation Loss: 0.1953\n",
            "Epoch 16/25, Training Loss: 0.1746\n",
            "Epoch 16/25, Validation Loss: 0.1840\n",
            "Epoch 17/25, Training Loss: 0.1645\n",
            "Epoch 17/25, Validation Loss: 0.1769\n",
            "Epoch 18/25, Training Loss: 0.1727\n",
            "Epoch 18/25, Validation Loss: 0.1839\n",
            "Epoch 19/25, Training Loss: 0.1553\n",
            "Epoch 19/25, Validation Loss: 0.1792\n",
            "Epoch 20/25, Training Loss: 0.1654\n",
            "Epoch 20/25, Validation Loss: 0.1782\n",
            "Epoch 21/25, Training Loss: 0.1740\n",
            "Epoch 21/25, Validation Loss: 0.1823\n",
            "Epoch 22/25, Training Loss: 0.1651\n",
            "Epoch 22/25, Validation Loss: 0.1754\n",
            "Epoch 23/25, Training Loss: 0.1700\n",
            "Epoch 23/25, Validation Loss: 0.1797\n",
            "Epoch 24/25, Training Loss: 0.1683\n",
            "Epoch 24/25, Validation Loss: 0.1784\n",
            "Epoch 25/25, Training Loss: 0.1575\n",
            "Epoch 25/25, Validation Loss: 0.1779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
        "\n",
        "# Function to evaluate model on validation set\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            outputs = model(images)['out']\n",
        "            preds = torch.argmax(outputs, dim=1)  # Get the class with max probability for each pixel\n",
        "            all_preds.append(preds.cpu().numpy())  # Store predictions\n",
        "            all_true.append(masks.cpu().numpy())   # Store ground truths\n",
        "\n",
        "    # Convert lists to numpy arrays for evaluation\n",
        "    y_pred = np.concatenate(all_preds, axis=0).flatten()\n",
        "    y_true = np.concatenate(all_true, axis=0).flatten()\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(y_true == y_pred)\n",
        "\n",
        "    # Calculate IoU (Jaccard index)\n",
        "    iou = jaccard_score(y_true, y_pred, pos_label=1)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    precision = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_true, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_true, y_pred, pos_label=1)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"IoU for water class: {iou:.4f}\")\n",
        "    print(f\"Precision for water class: {precision:.4f}\")\n",
        "    print(f\"Recall for water class: {recall:.4f}\")\n",
        "    print(f\"F1-score for water class: {f1:.4f}\")\n",
        "\n",
        "    return accuracy, iou, precision, recall, f1\n",
        "\n",
        "# Evaluate the model\n",
        "y_true, y_pred = evaluate_model(model, val_loader)\n",
        "\n",
        "# Calculate and display the metrics\n",
        "accuracy, iou, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
        "\n",
        "print(f\"Validation Results - Accuracy: {accuracy:.4f}, IoU: {iou:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT9vgGazE4Kh",
        "outputId": "dfd0631b-bfe2-4d0b-d810-6b16d9ec8fa4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9305\n",
            "IoU for water class: 0.7846\n",
            "Precision for water class: 0.8959\n",
            "Recall for water class: 0.8633\n",
            "F1-score for water class: 0.8793\n",
            "Validation Results - Accuracy: 0.9305, IoU: 0.7846, Precision: 0.8959, Recall: 0.8633, F1-score: 0.8793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvhIACf4WvK9",
        "outputId": "349ffc06-412b-4f91-ba57-6859c9f93715"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1]],\n",
              "\n",
              "         [[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0, 0, 0,  ..., 1, 1, 1],\n",
              "          [0, 0, 0,  ..., 1, 1, 1],\n",
              "          [0, 0, 0,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
              "\n",
              "\n",
              "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 1, 1, 1],\n",
              "          [0, 0, 0,  ..., 1, 1, 1],\n",
              "          [0, 0, 0,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
              "\n",
              "\n",
              "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1]],\n",
              "\n",
              "         [[1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
              "\n",
              "\n",
              "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1]],\n",
              "\n",
              "         [[1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 1]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opmjBwJQW_5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}